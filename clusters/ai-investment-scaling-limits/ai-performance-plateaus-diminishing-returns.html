<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Performance Plateaus & Diminishing Returns - MacroRoundup</title>
    <link rel="stylesheet" href="../../css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>AI Performance Plateaus & Diminishing Returns</h1>
            <div class="subtitle">43 articles · Parent: AI Investment & Scaling Limits</div>
        </div>
    </header>
    
    <div class="container">
        <nav>
            <a href="index.html">← AI Investment & Scaling Limits</a>
            <a href="../../index.html">Home</a>
        </nav>
        
        <div class="card">
            <h2>Description</h2>
            <p>This subcluster examines evidence that AI model performance improvements are decelerating despite massive investments. Articles analyze technical limitations in scaling laws, underwhelming releases like GPT-5 and Gemini 3, and constraints from data availability and compute resources. Sources include technology analysts like Kedrosky, research institutions like MIT and Bridgewater, and industry observers documenting diminishing returns on AI R&D spending. The focus centers on performance metrics, model capabilities, and technical bottlenecks rather than financial flows. Unlike its sibling subcluster on capital expenditure surges, this group emphasizes output stagnation and efficiency concerns rather than input investment trends and spending patterns.</p>
        </div>
        
        <div class="card">
            <h2>Most Representative Articles</h2>
            <ul class="article-list">
                
        <li>
            <div class="title">1. The rate of performance improvement of large language models may be slowing, as models face both data availability and compute constraints. GPT-5’s launch underwhelmed many in the sector.</div>
            <div class="meta">
                Financial Times · 2025-08-18
                <span class="similarity">Similarity: 0.76</span>
            </div>
        </li>
        
        <li>
            <div class="title">2. Following tepid reactions to the release of GTP-5, Joe Wang observes, "It is looking more like companies are spending hundreds of billions on rapidly depreciating GPUs that produce a commoditized product that most clients only modestly benefit from."</div>
            <div class="meta">
                Fed Guy Blog · 2025-08-18
                <span class="similarity">Similarity: 0.76</span>
            </div>
        </li>
        
        <li>
            <div class="title">3. Boston Consulting Group consultants using AI finished 12.2% more tasks on average, completed tasks 25.1% more quickly, and produced 40% higher quality results than a control group without AI. @emollick</div>
            <div class="meta">
                One Useful Thing · 2023-09-18
                <span class="similarity">Similarity: 0.76</span>
            </div>
        </li>
        
        <li>
            <div class="title">4. Chinese company DeepSeek’s new AI model rivals Claude 3.5 Sonnet but cost just $5.6M to train—100x cheaper than Meta’s Llama 3. Given chip export controls, the team “delivered this superb model through ingenuity rather than brute force.” @azeem</div>
            <div class="meta">
                Exponential View · 2025-01-03
                <span class="similarity">Similarity: 0.76</span>
            </div>
        </li>
        
        <li>
            <div class="title">5. Current AI models are “impressive but bounded.” After vastly underestimating the limits of scaling, Paul Kedrosky argues, “labs are returning to older, harder problems…a reminder that the next five years will be nothing like the last five.”</div>
            <div class="meta">
                Applied Complexity · 2025-12-15
                <span class="similarity">Similarity: 0.76</span>
            </div>
        </li>
        
            </ul>
        </div>
        
        <div class="card">
            <h2>Edge Cases (Boundary Articles)</h2>
            <ul class="article-list">
                
        <li>
            <div class="title">1. Torsten Sløk shows that banks are playing a smaller role as a provider of credit. Bank lending declined from ~27% of total non-financial corporate debt prior to the crisis to ~20% today.</div>
            <div class="meta">
                Apollo · 2025-05-09
                <span class="similarity">Similarity: 0.33</span>
            </div>
            <div class="meta">Almost classified as: P1_S2</div>
            <div class="edge-reason">This article is clearly misclassified as it discusses banking sector trends and corporate debt financing rather than AI performance or scaling limitations. It should be moved to the "Credit Markets and Corporate Borrowing Costs" cluster since it directly analyzes changes in bank lending's share of corporate debt markets, which is exactly what that cluster covers.</div>
        </li>
        
        <li>
            <div class="title">2. Technology newsletter publisher @benthompson tested @OpenAI’s ChatGPT on his daughter’s homework assignment about Thomas Hobbes and received “a confident answer, complete with supporting evidence, and it is completely wrong.”</div>
            <div class="meta">
                Stratechery · 2022-12-07
                <span class="similarity">Similarity: 0.39</span>
            </div>
            <div class="meta">Almost classified as: P7_S1</div>
            <div class="edge-reason">This article is borderline because while it demonstrates a specific AI failure (confidently providing incorrect information), it's more of an anecdotal example of AI limitations rather than systematic evidence of performance plateaus or diminishing returns from scaling investments. The article focuses on a singular instance of ChatGPT producing wrong answers rather than analyzing broader trends in AI model performance improvements or technical scaling limitations.</div>
        </li>
        
        <li>
            <div class="title">3. In a randomized clinical trial of diagnostic reasoning, physicians using conventional resources scored 74%, while those using GPT-4 scored 76%. GPT-4 alone scored 16pp higher than the conventional resources group.</div>
            <div class="meta">
                Journal of the American Medical Association · 2024-11-22
                <span class="similarity">Similarity: 0.43</span>
            </div>
            <div class="meta">Almost classified as: P10_S1</div>
            <div class="edge-reason">This article is borderline because while it shows GPT-4's strong performance in medical diagnosis, it doesn't actually demonstrate performance plateaus or diminishing returns - instead, it shows AI significantly outperforming conventional methods. The article would better fit the alternative cluster about management performance and market outcomes since it focuses on practical implementation results and physician performance metrics rather than technical scaling limitations.</div>
        </li>
        
            </ul>
        </div>
        
        <div class="card">
            <h2>Relationship Dendrogram</h2>
            <div class="dendrogram">
                <img src="../../dendrograms/P11_S1_dendrogram.png" alt="Relationship Dendrogram" onerror="this.style.display='none'">
            </div>
        </div>
        
        <div class="card">
            <h2>Related Subclusters</h2>
            <div class="related-links">
                <a href="#">P10_S1 (0.62)</a><a href="#">P3_S2 (0.61)</a><a href="#">P6_S1 (0.60)</a><a href="#">P3_S8 (0.57)</a><a href="#">P5_S6 (0.57)</a>
            </div>
        </div>
    </div>
    
    <footer>
        MacroRoundup Taxonomy Analysis
    </footer>
</body>
</html>