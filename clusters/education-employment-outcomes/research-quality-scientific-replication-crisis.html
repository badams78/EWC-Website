<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Quality & Scientific Replication Crisis - MacroRoundup</title>
    <link rel="stylesheet" href="../../css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>Research Quality & Scientific Replication Crisis</h1>
            <div class="subtitle">17 articles · Parent: Education & Employment Outcomes</div>
        </div>
    </header>
    
    <div class="container">
        <nav>
            <a href="index.html">← Education & Employment Outcomes</a>
            <a href="../../index.html">Home</a>
        </nav>
        
        <div class="card">
            <h2>Description</h2>
            <p>This subcluster examines systemic problems in academic research methodology and scientific publishing that undermine evidence-based policy formation. Core themes include replication failures, research misconduct, publication bias, and the politicization of science. Articles typically analyze large-scale meta-studies, retraction databases, and empirical reviews of research quality across disciplines. Unlike sibling subclusters that focus on specific educational or economic outcomes, this cluster critiques the foundational research infrastructure itself, questioning consensus formation and methodological rigor that informs education and employment policy decisions.</p>
        </div>
        
        <div class="card">
            <h2>Most Representative Articles</h2>
            <ul class="article-list">
                
        <li>
            <div class="title">1. A 12-point checklist for when to doubt a scientific consensus: recent analyses reveal significant issues in the reliability of economic studies, with up to 20% fudged.</div>
            <div class="meta">
                American Enterprise Institute · 2020-09-17
                <span class="similarity">Similarity: 0.81</span>
            </div>
        </li>
        
        <li>
            <div class="title">2. A recent study found 10-20% of results in top American journals may be questionable, raising concerns about the reliability of economic research.</div>
            <div class="meta">
                The Economist · 2016-01-25
                <span class="similarity">Similarity: 0.79</span>
            </div>
        </li>
        
        <li>
            <div class="title">3. Only 39% of psychology papers published in 2015 were replicable, highlighting a significant issue in scientific research reliability.</div>
            <div class="meta">
                The Economist · 2016-02-08
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
        <li>
            <div class="title">4. Research in @ScienceAdvances finds papers that fail to replicate receive more citations than those that do replicate, even after publication of replication failures.</div>
            <div class="meta">
                Science · 2021-06-15
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
        <li>
            <div class="title">5. A review of nearly 7,000 empirical economics studies found 90% of studies in half of research areas were underpowered, with 80% of remaining studies exaggerating results.</div>
            <div class="meta">
                The Economist · 2020-09-17
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
            </ul>
        </div>
        
        <div class="card">
            <h2>Edge Cases (Boundary Articles)</h2>
            <ul class="article-list">
                
        <li>
            <div class="title">1. Diversity in communities correlates with a decline in social capital, impacting civic engagement & trust. Residents in diverse settings are less likely to vote, volunteer, or engage in community projects, with trust levels dropping by nearly 50%.</div>
            <div class="meta">
                Boston Globe · 2015-04-23
                <span class="similarity">Similarity: 0.57</span>
            </div>
            <div class="meta">Almost classified as: P7_S1</div>
            <div class="edge-reason">This article is borderline because while it presents social science research findings about diversity and social capital, it appears to report empirical results rather than examine the methodological problems, replication failures, or publishing issues that define the "Research Quality & Scientific Replication Crisis" cluster. The content is more focused on substantive political/social findings about community engagement and trust, which aligns better with political analysis clusters like the alternative "Gender & Age Gaps in Political Support."</div>
        </li>
        
        <li>
            <div class="title">2. The inspection paradox distorts sample data by overrepresenting larger groups, leading to biased averages: e.g., average class sizes appear 90 vs. an actual 35, and prison sentences average 13 years vs. an actual 3.6 years, skewing perceptions.</div>
            <div class="meta">
                Science · 2021-08-19
                <span class="similarity">Similarity: 0.58</span>
            </div>
            <div class="meta">Almost classified as: P10_S1</div>
            <div class="edge-reason">This article is borderline because while it addresses a fundamental statistical bias that can distort research findings (the inspection paradox), it focuses more on a specific methodological phenomenon rather than the broader systemic issues of research quality, replication failures, and publishing problems that define the cluster. The content is more about statistical sampling bias mechanics than the institutional and structural problems undermining scientific research quality.</div>
        </li>
        
        <li>
            <div class="title">3. Researchers who narrowly missed securing grants but persisted in reapplying outperformed those who succeeded initially, achieving 36% more citations & 39% more high-impact papers over a decade.</div>
            <div class="meta">
                The Economist · 2019-06-06
                <span class="similarity">Similarity: 0.58</span>
            </div>
            <div class="meta">Almost classified as: P10_S1</div>
            <div class="edge-reason">This article is borderline because while it presents research findings about academic performance, it focuses on the positive outcomes of grant rejection and researcher persistence rather than addressing the core methodological problems, replication failures, or publishing issues that define the Research Quality & Scientific Replication Crisis cluster. The study appears to demonstrate successful research methodology (tracking long-term citation impacts) rather than critiquing flawed research practices or systemic problems in academia.</div>
        </li>
        
            </ul>
        </div>
        
        <div class="card">
            <h2>Relationship Dendrogram</h2>
            <div class="dendrogram">
                <img src="../../dendrograms/P10_S11_dendrogram.png" alt="Relationship Dendrogram" onerror="this.style.display='none'">
            </div>
        </div>
        
        <div class="card">
            <h2>Related Subclusters</h2>
            <div class="related-links">
                <a href="#">P6_S1 (0.63)</a><a href="#">P3_S2 (0.61)</a><a href="#">P8_S3 (0.61)</a><a href="#">P8_S1 (0.56)</a><a href="#">P13_S3 (0.56)</a>
            </div>
        </div>
    </div>
    
    <footer>
        MacroRoundup Taxonomy Analysis
    </footer>
</body>
</html>