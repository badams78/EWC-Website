<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scientific Research Reliability & Replication Crisis - MacroRoundup</title>
    <link rel="stylesheet" href="../../css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>Scientific Research Reliability & Replication Crisis</h1>
            <div class="subtitle">17 articles · Parent: Education & Employment Outcomes</div>
        </div>
    </header>
    
    <div class="container">
        <nav>
            <a href="index.html">← Education & Employment Outcomes</a>
            <a href="../../index.html">Home</a>
        </nav>
        
        <div class="card">
            <h2>Description</h2>
            <p>This subcluster examines the methodological integrity and reproducibility challenges plaguing academic research, particularly in economics and social sciences. Articles focus on replication crises, research misconduct, publication bias, and statistical manipulation affecting study reliability. Common sources include peer-reviewed journals like Nature and Science Advances, along with meta-analyses of empirical studies. The content addresses retraction rates, grant funding impacts on research quality, consensus evaluation frameworks, and politicization effects on scientific objectivity. Unlike sibling subclusters that analyze specific educational or employment outcomes, this group critically evaluates the research methodologies and institutional processes that generate the evidence underlying policy decisions in education and labor markets.</p>
        </div>
        
        <div class="card">
            <h2>Most Representative Articles</h2>
            <ul class="article-list">
                
        <li>
            <div class="title">1. A 12-point checklist for when to doubt a scientific consensus: recent analyses reveal significant issues in the reliability of economic studies, with up to 20% fudged.</div>
            <div class="meta">
                American Enterprise Institute · 2020-09-17
                <span class="similarity">Similarity: 0.81</span>
            </div>
        </li>
        
        <li>
            <div class="title">2. A recent study found 10-20% of results in top American journals may be questionable, raising concerns about the reliability of economic research.</div>
            <div class="meta">
                The Economist · 2016-01-25
                <span class="similarity">Similarity: 0.79</span>
            </div>
        </li>
        
        <li>
            <div class="title">3. Only 39% of psychology papers published in 2015 were replicable, highlighting a significant issue in scientific research reliability.</div>
            <div class="meta">
                The Economist · 2016-02-08
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
        <li>
            <div class="title">4. Research in @ScienceAdvances finds papers that fail to replicate receive more citations than those that do replicate, even after publication of replication failures.</div>
            <div class="meta">
                Science · 2021-06-15
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
        <li>
            <div class="title">5. A review of nearly 7,000 empirical economics studies found 90% of studies in half of research areas were underpowered, with 80% of remaining studies exaggerating results.</div>
            <div class="meta">
                The Economist · 2020-09-17
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
            </ul>
        </div>
        
        <div class="card">
            <h2>Edge Cases (Boundary Articles)</h2>
            <ul class="article-list">
                
        <li>
            <div class="title">1. Diversity in communities correlates with a decline in social capital, impacting civic engagement & trust. Residents in diverse settings are less likely to vote, volunteer, or engage in community projects, with trust levels dropping by nearly 50%.</div>
            <div class="meta">
                Boston Globe · 2015-04-23
                <span class="similarity">Similarity: 0.57</span>
            </div>
            <div class="meta">Almost classified as: P7_S1</div>
            <div class="edge-reason">This article is borderline for the "Scientific Research Reliability & Replication Crisis" cluster because while it presents statistical claims about diversity and social capital that could be subject to replication issues, the article itself is a news report discussing research findings rather than examining methodological problems or reproducibility challenges in academic research. The content is more aligned with political/social demographic analysis (hence the higher similarity to the gender/age political preference cluster) rather than focusing on research methodology and scientific integrity concerns.</div>
        </li>
        
        <li>
            <div class="title">2. The inspection paradox distorts sample data by overrepresenting larger groups, leading to biased averages: e.g., average class sizes appear 90 vs. an actual 35, and prison sentences average 13 years vs. an actual 3.6 years, skewing perceptions.</div>
            <div class="meta">
                Science · 2021-08-19
                <span class="similarity">Similarity: 0.58</span>
            </div>
            <div class="meta">Almost classified as: P10_S1</div>
            <div class="edge-reason">This article is borderline because while it discusses a statistical bias that could affect research validity (the inspection paradox), it focuses on a specific sampling methodology issue rather than the broader systemic problems of research reproducibility and replication failures that define the cluster. The article is more about explaining a particular statistical phenomenon than examining the methodological integrity crisis in academic research.</div>
        </li>
        
        <li>
            <div class="title">3. Researchers who narrowly missed securing grants but persisted in reapplying outperformed those who succeeded initially, achieving 36% more citations & 39% more high-impact papers over a decade.</div>
            <div class="meta">
                The Economist · 2019-06-06
                <span class="similarity">Similarity: 0.58</span>
            </div>
            <div class="meta">Almost classified as: P10_S1</div>
            <div class="edge-reason">This article is borderline because while it presents research findings about academic performance, it focuses on individual researcher career outcomes and productivity metrics rather than examining the core methodological issues, reproducibility problems, or systemic reliability challenges that define the replication crisis literature. The content is more aligned with performance analysis and career trajectory studies than with the fundamental questions about research integrity and methodological rigor that characterize the assigned cluster.</div>
        </li>
        
            </ul>
        </div>
        
        <div class="card">
            <h2>Relationship Dendrogram</h2>
            <div class="dendrogram">
                <img src="../../dendrograms/P10_S11_dendrogram.png" alt="Relationship Dendrogram" onerror="this.style.display='none'">
            </div>
        </div>
        
        <div class="card">
            <h2>Related Subclusters</h2>
            <div class="related-links">
                <a href="#">P6_S1 (0.63)</a><a href="#">P3_S2 (0.61)</a><a href="#">P8_S3 (0.61)</a><a href="#">P8_S1 (0.56)</a><a href="#">P13_S3 (0.56)</a>
            </div>
        </div>
    </div>
    
    <footer>
        MacroRoundup Taxonomy Analysis
    </footer>
</body>
</html>